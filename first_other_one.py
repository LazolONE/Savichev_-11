# -*- coding: utf-8 -*-
"""first_one.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l-k17E1jq0JsVVLlQhXhj53bRQzi2caE
"""

import re
from collections import Counter

def read_text_file(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        return file.read()

def clean_text(text):
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'\[\d+\]', '', text)
    return text.strip()

def count_word_frequencies(text):
    words = re.findall(r'\b\w+\b', text.lower())
    return Counter(words)

def find_word_context(text, target_word, left_len, right_len, cut_length=False, output_file='context.txt'):
    cleaned = re.sub(r'[^\w\s]', '', text)
    words = cleaned.lower().split()
    target_word = target_word.lower()

    with open(output_file, 'w', encoding='utf-8') as f:
        for i, word in enumerate(words):
            if word == target_word:
                if cut_length:
                    sentences = re.split(r'(?<=[.!?])\s+', text.lower())
                    current_sentence = next((s for s in sentences if target_word in s.split()), '')
                    sent_words = current_sentence.split()
                    try:
                        pos = sent_words.index(target_word)
                        left = ' '.join(sent_words[max(0, pos-left_len):pos])
                        right = ' '.join(sent_words[pos+1:pos+right_len+1])
                        output = f"{left} [{word.upper()}] {right}\n"
                    except ValueError:
                        continue
                else:
                    left_start = max(0, i - left_len)
                    left_context = ' '.join(words[left_start:i])
                    right_end = min(len(words), i + 1 + right_len)
                    right_context = ' '.join(words[i+1:right_end])
                    output = f"{left_context} [{word.upper()}] {right_context}\n"

                print(output, end='')
                f.write(output)

if __name__ == "__main__":
    try:
        file_path = input("Введите имя файла: ")
        text = read_text_file(file_path)

        cleaned_text = clean_text(text)
        word_counts = count_word_frequencies(cleaned_text)
        print("10 самых частых слов:", word_counts.most_common(10))

        target = input("Введите слово для поиска контекста: ")

        find_word_context(
            text=cleaned_text,
            target_word=target,
            left_len=5,
            right_len=5,
            cut_length=True,
            output_file="context_output.txt"
        )
    except Exception as e:
        print(f"Ошибка: {e}")